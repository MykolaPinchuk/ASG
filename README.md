# ASG

ASG is a small, deterministic, replayable turn-based strategy game designed as an evaluation environment for LLM agents.

## For agents
Start here (in order):
- `agents.md` (generated by `context-manager-1`; general instructions)
- `repo_workflow.md` (repo-specific workflow: triggers + procedures)
- `onboarding.md` (how onboarding works here)
- `HANDOFF.md` (current state / next steps)
- `REPO_MAP.md` (index of important files)
- `agent_logs/current.md` (live execution log; history indexed in `agent_logs/INDEX.md`)

## Key docs (MVP v0)
- `docs/planning/MVP_SPEC.md` — normative rules/spec (source of truth)
- `docs/planning/IMPLEMENTATION_PLAN.md` — milestones and deliverables
- `docs/planning/ROADMAP.md` — post-MVP direction
- `scenarios/scenario_01.json` — Scenario 01 data
- `schemas/replay.schema.json` — replay validation schema
- `schemas/agent_api.schema.json` — agent HTTP wire schema (future)

## Quickstart (run + watch)
- Install deps: `npm install`
- Run a match (writes JSON under `replays/`): `npm run match -- --seed 1 --p1 greedy --p2 random`
- Intermediate bot (mix of greedy + random): `npm run match -- --seed 1 --p1 mix --p2 random --mix-greedy-prob 0.5`
- Validate replay: `npm run validate:replay -- replays/<file>.json`
- Check determinism (same seed/actions ⇒ same replay, ignoring `createdAt`): `npm run check:determinism -- --seed 1 --p1 greedy --p2 random`
- Batch run (quick win/draw rate glance): `npm run batch -- --start 1 --count 20 --p1 greedy --p2 greedy`
- Batch report (more metrics): `npm run report -- --start 1 --count 50 --p1 greedy --p2 greedy --format text`
- Open the viewer: `viewer/index.html` and load the replay file via file picker (or drag/drop).

## Agent integration (HTTP)
The match runner can call an external agent over HTTP (`POST /act`) per `docs/planning/AGENT_API_SPEC.md`.

- Start a local stub agent server (no API keys needed): `npm run agent:stub`
- Start the full agent server (supports `stub` + `openai_compat`): `npm run agent:server -- --provider stub`
- Run a match vs the agent:
  - `npm run match -- --seed 1 --p1 greedy --p2 agent --agent-url http://127.0.0.1:8787`
  - Optional: log raw request/response per ply under `runs/`: add `--agent-log-dir runs/agent_io`
  - If using a real LLM and you see timeouts, increase the client timeout: add `--agent-timeout-ms 60000` (default is 60000).

The replay viewer shows controller/model metadata (when present) in the **Players** panel.

### Real LLM (OpenAI-compatible providers)
Run the agent server with `openai_compat` and point it at an OpenAI-compatible endpoint (e.g. OpenRouter).
Keys stay local (env vars / `secrets/`), never committed.

Example (OpenRouter):
- `export ASG_OPENROUTER_API_KEY='...'`
- `npm run agent:server -- --provider openai_compat --provider-name openrouter --base-url https://openrouter.ai/api/v1`
  - Defaults to `x-ai/grok-4.1-fast`; override with `--model <model_id>`

### OSS model auto-pick (baselines + sweeps)
ASG supports `--model auto` for OpenAI-compatible OSS providers. There are two configs:
- `configs/oss_baselines.json` — small, stable baseline set (recommended default for day-to-day runs)
- `configs/oss_models.json` — broader allowlist/priority list (derived from TML-bench; useful for sweeps)

- Auto-pick a baseline model (Chutes):
  - `npm run agent:server -- --provider openai_compat --provider-name chutes --base-url https://llm.chutes.ai/v1 --keys-file /path/to/provider_apis.txt --model auto --models-config configs/oss_baselines.json`
- Auto-pick a baseline model (NanoGPT):
  - `npm run agent:server -- --provider openai_compat --provider-name nanogpt --keys-file /path/to/provider_apis.txt --model auto --models-config configs/oss_baselines.json`

Tip: set `ASG_MODELS_CONFIG=configs/oss_baselines.json` to avoid passing `--models-config` each time.

Quick smoke test (1 LLM decision only): add `--turn-cap-plies 2` to `npm run match ...`.

### Baseline check: agent vs random
Runs a small sweep (starts a local agent server automatically) and prints win/draw rates:
- `npm run agent:vs-random -- --provider-name nanogpt --keys-file secrets/provider_apis.txt --model auto --turn-cap-plies 20 --start 1 --count 2`

### Baseline check: Grok vs Greedy (cost-capped)
Runs Grok (`x-ai/grok-4.1-fast`) vs `greedy` and always saves replays (hard cap: max 3 games per run):
- `npm run eval:grok-vs-greedy`

### Debug: summarize agent I/O logs (local)
Summarizes `runs/agent_io/` into per-match counts: pass turns, provider-error turns (from rationale), timeouts, HTTP/parse errors, and latency percentiles:
- `npm run analyze:agent-io -- --dir runs/agent_io --limit 20`

### Debug: OSS leaderboard from JSONL
Aggregates `runs/live/*.jsonl` into a per-provider/model table (sorted by win rate, then reliability):
- `npm run oss:rank -- --dir runs/live --format text --limit 30`

List models from a provider (requires provider access; some endpoints need an API key):
- `npm run agent:list-models -- --provider openrouter --base-url https://openrouter.ai/api/v1 --format text --limit 50`
- `npm run agent:list-models -- --provider nanogpt --keys-file /path/to/provider_apis.txt --format text --limit 50`
- `npm run agent:list-models -- --provider chutes --base-url https://llm.chutes.ai/v1 --keys-file /path/to/provider_apis.txt --format text --limit 50`
  - Add `--models-config configs/oss_models.json` to filter to the OSS allowlist (default `--only-allowed=true`).

Provider-specific env vars (optional convenience):
- `ASG_OPENROUTER_BASE_URL`, `ASG_OPENROUTER_API_KEY`, `ASG_OPENROUTER_MODEL`
- `ASG_CHUTES_BASE_URL`, `ASG_CHUTES_API_KEY`, `ASG_CHUTES_MODEL`
- `ASG_NANOGPT_BASE_URL`, `ASG_NANOGPT_API_KEY`, `ASG_NANOGPT_MODEL`

You can also run the agent server using a `--keys-file` (same format as TML-bench `secrets/provider_apis.txt`):
- `npm run agent:server -- --provider openai_compat --provider-name nanogpt --keys-file /path/to/provider_apis.txt --model <model_id>`

## Agent triggers
- `Onboard` — deterministic onboarding
- `checkpoint` — safe checkpoint commit
- `handoff` / `wrap up` — update handoff docs, rotate logs, and create a safe handoff commit

## Context manager integration
To generate `agents.md` and `business_context.md`:
- `python /path/to/context-manager-1/sync_context.py --repo /path/to/ASG`
